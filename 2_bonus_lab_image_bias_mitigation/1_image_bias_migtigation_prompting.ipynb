{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18febc2a-572f-4bd1-aa4b-2b1669612bdb",
   "metadata": {},
   "source": [
    "# Part 2 - Mitigating bias in text-image models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af936b1c-1faf-4838-ab69-ea9bb29a11e8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --no-build-isolation --force-reinstall \\\n",
    "    dependencies/awscli-*-py3-none-any.whl \\\n",
    "    dependencies/boto3-*-py3-none-any.whl \\\n",
    "    dependencies/botocore-*-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a016cd3a-2d01-47d3-9678-af17a53bc4f0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install langchain --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aea9cac-59c2-4931-9cea-c8827ac06629",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip --quiet\n",
    "# !pip install protobuf==3.20 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bf567e-75d8-4924-b8a4-c119855f9f46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441a4c3b-168e-4643-91da-3ab89de3ea0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "from typing import Union\n",
    "import io\n",
    "import base64\n",
    "import boto3\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock\n",
    "boto3_bedrock = bedrock.get_bedrock_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708bef56-396b-4fe1-b9c4-410946edde75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def invoke_image_gen(prompt, negative_prompts):\n",
    "    request = json.dumps({\n",
    "    \"text_prompts\": (\n",
    "        [{\"text\": prompt, \"weight\": 1.0}]\n",
    "        + [{\"text\": negprompt, \"weight\": -1.0} for negprompt in negative_prompts]\n",
    "    ),\n",
    "    \"cfg_scale\": 5,\n",
    "    \"seed\": 5450,\n",
    "    \"steps\": 70,\n",
    "    \"style_preset\": style_preset,\n",
    "    })\n",
    "    modelId = \"stability.stable-diffusion-xl\"\n",
    "\n",
    "    response = boto3_bedrock.invoke_model(body=request, modelId=modelId)\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "    print(response_body[\"result\"])\n",
    "    base_64_img_str = response_body[\"artifacts\"][0].get(\"base64\")\n",
    "    print(f\"{base_64_img_str[0:80]}...\")\n",
    "    return base_64_img_str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0e4285-6665-48a3-bb4c-aa0681e93928",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"picture of a doctor\"\n",
    "negative_prompts = [\"bias\", \n",
    "                    \"discriminatory\",\n",
    "                    \"poorly rendered\",\n",
    "                    \"poor background details\",\n",
    "                    \"poorly drawn features\",\n",
    "                    \"disfigured features\",\n",
    "                   ]\n",
    "style_preset = \"photographic\" \n",
    "output = invoke_image_gen(prompt, negative_prompts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863e5623-e663-4567-b761-17f564b7e298",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_1 = Image.open(io.BytesIO(base64.decodebytes(bytes(output, \"utf-8\"))))\n",
    "image_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4278e4c8-ca45-4141-8b4c-d0ff1ffd243d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_gender_inclusive = \"a picture of a doctor which is inclusive of male and female.\"\n",
    "\n",
    "output = invoke_image_gen(prompt_gender_inclusive, negative_prompts)\n",
    "image_1 = Image.open(io.BytesIO(base64.decodebytes(bytes(output, \"utf-8\"))))\n",
    "image_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfff991-567a-4623-9892-c429d5b9abc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_gender_color_inclusive = \"a picture of a doctor which is inclusive of male, female and color\"\n",
    "\n",
    "output = invoke_image_gen(text_gender_color_inclusive, negative_prompts)\n",
    "image_1 = Image.open(io.BytesIO(base64.decodebytes(bytes(output, \"utf-8\"))))\n",
    "image_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f070131e-979b-4df9-a97c-db0fb021bf1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_base = \"an picture of a nurse\"\n",
    "negative_prompts = [\"bias and discrimination against certain group of people\"]\n",
    "\n",
    "output = invoke_image_gen(text_base, negative_prompts)\n",
    "image_1 = Image.open(io.BytesIO(base64.decodebytes(bytes(output, \"utf-8\"))))\n",
    "image_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90bcd9a-b2de-4a50-84e9-e20772aeb9de",
   "metadata": {},
   "source": [
    "### Bias mitigation\n",
    "Steps:\n",
    "- Use a LLM to generate prompts which are non-discriminatory and try to remove bias from the prompt. \n",
    "- Use the generated prompt to create an image. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f13c2ee-1ac7-4dcc-86c9-973d2e599a70",
   "metadata": {},
   "source": [
    "#### Step 1: Create a chatbot application to generate inclusive prompts. \n",
    "The chatbot will make sure to ask relevant questions to the user before generating the prompt for `text-image` model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6451de64-2d68-41c4-b040-f9081a3b5c8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock\n",
    "boto3_bedrock = bedrock.get_bedrock_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ea5877-d969-4d38-9412-3b69bc159da8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "cl_llm = Bedrock(\n",
    "    model_id=\"anthropic.claude-v1\",\n",
    "    client=boto3_bedrock,\n",
    "    model_kwargs={\"max_tokens_to_sample\": 1000, \"temperature\":0},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c4448c-315e-4c9c-8a25-9b581f0eb66d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=cl_llm, verbose=True, memory=memory\n",
    ")\n",
    "\n",
    "print(conversation.predict(input=\"Hi there!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b990dc3-771d-433e-9071-860c853ef05c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "# turn verbose to true to see the full logs and documents\n",
    "conversation= ConversationChain(\n",
    "    llm=cl_llm, verbose=False, memory=ConversationBufferMemory() #memory_chain\n",
    ")\n",
    "\n",
    "# langchain prompts do not always work with all the models. This prompt is tuned for Claude\n",
    "chat_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a prompt generator, who generates prompts for text to image models.\n",
    "The AI is not biased and does not discriminate against certain groups of people. \n",
    "If AI detects bias in the question, AI asks relevant questions based on gender, race and color before responding.\n",
    "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "If the question has a class of human biengs AI will ask all of the following questions with examples before generating the prompt. \n",
    "<questions>\n",
    "- What is the gender of the subject in the picture? (e.g. male, female, transgender etc.)\n",
    "- What is the color of the subject in the image? (e.g. white, black, or brown etc.)\n",
    "- What is the race of the subject in the image? (e.g. African-american, latino, indian, korean, chineese, asian, etc.)\n",
    "</questions>\n",
    "Current conversation:\n",
    "{history}\n",
    "\n",
    "\n",
    "Human: {input}\n",
    "\n",
    "\n",
    "Assistant:\n",
    "\"\"\")\n",
    "\n",
    "conversation.prompt = chat_prompt\n",
    "\n",
    "print(conversation.predict(input=\"Hi there!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94850251-d4ba-43d8-be97-e16f2c292105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(conversation.predict(input=\"picture of a doctor.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec4907a-3811-4c25-9ea1-c645d6166449",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = conversation.predict(input=\"Hispanic brown female\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62b718d-bc89-4e7c-8cfc-fe2a8de460dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## optional to run, only if the model asks you for revised prompt you can uncomment and try it.\n",
    "# response = conversation.predict(input=\"yes\")\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059d3756-9569-47f0-9098-cd10866360cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = response\n",
    "negative_prompts = [\n",
    "    \"poorly rendered\",\n",
    "    \"poor background details\",\n",
    "    \"poorly drawn figure\",\n",
    "    \"disfigured features\",\n",
    "]\n",
    "style_preset = \"photographic\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43c710d-2879-4657-9934-5e6296d2ddb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request = json.dumps({\n",
    "    \"text_prompts\": (\n",
    "        [{\"text\": prompt, \"weight\": 1.0}]\n",
    "        + [{\"text\": negprompt, \"weight\": -1.0} for negprompt in negative_prompts]\n",
    "    ),\n",
    "    \"cfg_scale\": 5,\n",
    "    \"seed\": 5450,\n",
    "    \"steps\": 70,\n",
    "    \"style_preset\": style_preset,\n",
    "})\n",
    "modelId = \"stability.stable-diffusion-xl\"\n",
    "\n",
    "response = boto3_bedrock.invoke_model(body=request, modelId=modelId)\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "print(response_body[\"result\"])\n",
    "base_64_img_str = response_body[\"artifacts\"][0].get(\"base64\")\n",
    "print(f\"{base_64_img_str[0:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409a7152-367e-47aa-af26-a30f5a50669f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "image_1 = Image.open(io.BytesIO(base64.decodebytes(bytes(base_64_img_str, \"utf-8\"))))\n",
    "image_1.save(\"data/image_1.png\")\n",
    "image_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b381f3b5-bc62-4334-b3cb-e3c7b8e4c168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
